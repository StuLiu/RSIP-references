@INPROCEEDINGS{7780460,
  author={J. {Redmon} and S. {Divvala} and R. {Girshick} and A. {Farhadi}},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={You Only Look Once: Unified, Real-Time Object Detection}, 
  year={2016},
  volume={},
  number={},
  pages={779-788},
  abstract={We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
  keywords={image classification;image representation;neural nets;object detection;you only look once;unified real-time object detection;object classifiers;bounding boxes;class probabilities;neural network;detection pipeline;detection performance;YOLO model;object representation;DPM;R-CNN;natural images;Computer architecture;Microprocessors;Object detection;Training;Real-time systems;Neural networks;Pipelines},
  doi={10.1109/CVPR.2016.91},
  ISSN={1063-6919},
  month={June},}
